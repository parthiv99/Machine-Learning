{"cells":[{"cell_type":"markdown","source":[">Parthiv Desai\n","\n",">CPCSC 483 - 03\n","\n",">FINAL PROJECT - Convolutional_neural_network"],"metadata":{"id":"C0isEzFeW3mM"}},{"cell_type":"markdown","source":["#Importing the libraries"],"metadata":{"id":"InPp7eNH31Xw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVhYyfcyz8yP"},"outputs":[],"source":["import tensorflow as tf #Import the TensorFlow library\n","from keras.preprocessing.image import ImageDataGenerator #Importing ImageDataGenerator for preprocessing images using Keras Library."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683061135744,"user":{"displayName":"Parthiv Desai","userId":"01304148201832182673"},"user_tz":420},"id":"k9xRYIcS0THH","outputId":"71a78922-9cf0-41cb-a120-f15fba6c98e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.12.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":173}],"source":["tf.__version__"]},{"cell_type":"markdown","source":["#Importing the dataset"],"metadata":{"id":"tmSdkEQj31de"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnOlFVA_ABQW"},"outputs":[],"source":["(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data() #Loading the mnist dataset into the google collab"]},{"cell_type":"markdown","source":["#Data Preprocessing"],"metadata":{"id":"D1GAN1fl31ab"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fo4e0U22ABUE"},"outputs":[],"source":["train_datagen = ImageDataGenerator(rescale = 1./255, shear_range=0.2,\n","                                   zoom_range= 0.2,horizontal_flip= True) #Preprocessing the training set, implementing feature scaling and image transformation.\n"]},{"cell_type":"code","source":["X_train_augmented = X_train * 255  # Undo normalization for data augmentation\n","X_train_augmented = X_train_augmented.reshape(X_train_augmented.shape[0], 28, 28, 1)  # Add channel information\n","training_set = train_datagen.flow(X_train_augmented, y_train, batch_size=32) #Connecting the X_train_augmented to the image flow from the ImageGenerator dictionary. It will eventually be added to the CNN.\n"],"metadata":{"id":"h-N6BBmLFCkl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TprjjnUZCm01"},"outputs":[],"source":["test_datagen = ImageDataGenerator(rescale = 1./255, shear_range=0.2,\n","                                   zoom_range= 0.2,horizontal_flip= True) #Similarly, implementing the testing set,implementing feature scaling and image transformation.\n"]},{"cell_type":"code","source":["X_test_reshaped = X_test.reshape(X_test.shape[0], 28, 28, 1)  # Add channel information\n","test_set = test_datagen.flow(X_test_reshaped, y_test, batch_size=32)"],"metadata":{"id":"kS7ci4saFLGm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Building the CNN"],"metadata":{"id":"1hqGjPj2WU05"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IWh7i3B9YxiD"},"outputs":[],"source":["cnn = tf.keras.models.Sequential() #Initialising the CNN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrV8zvi5Yxkr"},"outputs":[],"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[28,28,1])) #It is performing Convolution filters meaning implementing detectors that filter the data. We indicate kernel size as 3 for giving the detector a size for detecting. The reason is that we choose 1 out of 3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9uw3jS3Yxp9"},"outputs":[],"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) #Controlling or managing the slide of the stride by sizing it to 2 and assigning stride to 2 as well.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zod116-rYxna"},"outputs":[],"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) #We need another Convolutional layer but as we initialized the input_size first time, we do not need to mention it for any of the remaining layers.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJpLdhxtYxro"},"outputs":[],"source":["cnn.add(tf.keras.layers.Flatten()) #Flattening the layers using the tf.keras library.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KcyVPETkYxtZ"},"outputs":[],"source":["cnn.add(tf.keras.layers.Dense(units=128, activation='relu')) #Full connection is established \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SNJ5Zc_YxvN"},"outputs":[],"source":["cnn.add(tf.keras.layers.Dense(units=10, activation='softmax')) #Creating an output layer for compiling purposes\n"]},{"cell_type":"markdown","source":["#Training the CNN"],"metadata":{"id":"sm0qLltYWlK0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_C0A-oESYxxE"},"outputs":[],"source":["cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #Implementing the compilation of CNN model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJi2Zi-3Y-g1"},"outputs":[],"source":["from tensorflow.keras.utils import to_categorical #We need this library to convert the training and test set to target labels and eventually convert them to one-hot encode\n","\n","y_train_onehot = to_categorical(y_train, num_classes=10) #This converts catogorical data to binary understandable data and the num_classes is assigned to 10 for creating 10 unique classes for y_train.\n","y_test_onehot = to_categorical(y_test, num_classes=10) #This converts catogorical data to binary understandable data and the num_classes is assigned to 10 for creating 10 unique classes for y_test."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ST0GL2WlY-j4"},"outputs":[],"source":["training_set = train_datagen.flow(X_train_augmented, y_train_onehot, batch_size=32) #train_dataget contains all the requirements for ImageGenerator but it needs a flow function for implementing a batch size.\n","test_set = test_datagen.flow(X_test_reshaped, y_test_onehot, batch_size=32) #Similarly, test_dataget contains all the requirements for ImageGenerator but it needs a flow function for implementing a batch size."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFJWGLUHF3Ra","executionInfo":{"status":"ok","timestamp":1683060948737,"user_tz":420,"elapsed":2740108,"user":{"displayName":"Parthiv Desai","userId":"01304148201832182673"}},"outputId":"3270d7cd-7e18-4421-dffb-d14c9f002fec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","1875/1875 [==============================] - 83s 43ms/step - loss: 0.4799 - accuracy: 0.8419 - val_loss: 0.2531 - val_accuracy: 0.9308\n","Epoch 2/25\n","1875/1875 [==============================] - 82s 44ms/step - loss: 0.1904 - accuracy: 0.9402 - val_loss: 0.2098 - val_accuracy: 0.9438\n","Epoch 3/25\n","1875/1875 [==============================] - 83s 44ms/step - loss: 0.1400 - accuracy: 0.9554 - val_loss: 0.2299 - val_accuracy: 0.9412\n","Epoch 4/25\n","1875/1875 [==============================] - 80s 43ms/step - loss: 0.1155 - accuracy: 0.9636 - val_loss: 0.1905 - val_accuracy: 0.9473\n","Epoch 5/25\n","1875/1875 [==============================] - 86s 46ms/step - loss: 0.0973 - accuracy: 0.9688 - val_loss: 0.1697 - val_accuracy: 0.9551\n","Epoch 6/25\n","1875/1875 [==============================] - 97s 52ms/step - loss: 0.0864 - accuracy: 0.9726 - val_loss: 0.1822 - val_accuracy: 0.9490\n","Epoch 7/25\n","1875/1875 [==============================] - 81s 43ms/step - loss: 0.0768 - accuracy: 0.9759 - val_loss: 0.2584 - val_accuracy: 0.9375\n","Epoch 8/25\n","1875/1875 [==============================] - 85s 45ms/step - loss: 0.0678 - accuracy: 0.9785 - val_loss: 0.3186 - val_accuracy: 0.9236\n","Epoch 9/25\n","1875/1875 [==============================] - 85s 45ms/step - loss: 0.0627 - accuracy: 0.9791 - val_loss: 0.3018 - val_accuracy: 0.9209\n","Epoch 10/25\n","1875/1875 [==============================] - 88s 47ms/step - loss: 0.0580 - accuracy: 0.9813 - val_loss: 0.4116 - val_accuracy: 0.9027\n","Epoch 11/25\n","1875/1875 [==============================] - 85s 45ms/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.4928 - val_accuracy: 0.8829\n","Epoch 12/25\n","1875/1875 [==============================] - 87s 46ms/step - loss: 0.0504 - accuracy: 0.9840 - val_loss: 0.5788 - val_accuracy: 0.8671\n","Epoch 13/25\n","1875/1875 [==============================] - 81s 43ms/step - loss: 0.0438 - accuracy: 0.9859 - val_loss: 0.6256 - val_accuracy: 0.8562\n","Epoch 14/25\n","1875/1875 [==============================] - 85s 46ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 0.4654 - val_accuracy: 0.8878\n","Epoch 15/25\n","1875/1875 [==============================] - 87s 46ms/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 0.9314 - val_accuracy: 0.8157\n","Epoch 16/25\n","1875/1875 [==============================] - 94s 50ms/step - loss: 0.0409 - accuracy: 0.9862 - val_loss: 0.8310 - val_accuracy: 0.8360\n","Epoch 17/25\n","1875/1875 [==============================] - 107s 57ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.3703 - val_accuracy: 0.9112\n","Epoch 18/25\n","1875/1875 [==============================] - 92s 49ms/step - loss: 0.0363 - accuracy: 0.9880 - val_loss: 0.6693 - val_accuracy: 0.8650\n","Epoch 19/25\n","1875/1875 [==============================] - 91s 48ms/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 1.1675 - val_accuracy: 0.8042\n","Epoch 20/25\n","1875/1875 [==============================] - 105s 56ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 1.0607 - val_accuracy: 0.8013\n","Epoch 21/25\n","1875/1875 [==============================] - 94s 50ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 1.0347 - val_accuracy: 0.7855\n","Epoch 22/25\n","1875/1875 [==============================] - 88s 47ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 0.9843 - val_accuracy: 0.8293\n","Epoch 23/25\n","1875/1875 [==============================] - 84s 45ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 1.3754 - val_accuracy: 0.7500\n","Epoch 24/25\n","1875/1875 [==============================] - 83s 44ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.8962 - val_accuracy: 0.8111\n","Epoch 25/25\n","1875/1875 [==============================] - 81s 43ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.6313 - val_accuracy: 0.8633\n"]}],"source":["history = cnn.fit(x=training_set,validation_data=test_set,epochs=25) #Making the CNN model on the training set and evaluating it on the test set\n"]},{"cell_type":"markdown","source":["#Making a Single Prediction"],"metadata":{"id":"FW6kfOQIWvJ9"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing import image #This library helps in loading any image and assigning predict value to the image. Perform the training on it and add an extra dimension to the image. As we converted the set into binary, we have a 0 dimention for batch and 0 first element in that batch\n","test_image = image.load_img('/content/drive/MyDrive/te1.jpg', color_mode='grayscale', target_size=(28, 28)) #Load an image in grayscale form and assigning it a target size for visualising purposes.\n","test_image = image.img_to_array(test_image, data_format='channels_last') #Using the img_to_array for converting the input image to a NumPy array.\n","test_image = np.expand_dims(test_image, axis=(0, 3)) #Adding extra dimensions to the image and assigning size to it.\n","result = cnn.predict(test_image) #Enables prediction on the CNN model.\n","if result[0][0] == 1: #A simple if else implementation that checks if the result array is 0 or 1.\n","    prediction = 'dog'\n","else:\n","    prediction = 'cat'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yt5YsB-uMRZt","executionInfo":{"status":"ok","timestamp":1683061608126,"user_tz":420,"elapsed":174,"user":{"displayName":"Parthiv Desai","userId":"01304148201832182673"}},"outputId":"aa5ecc37-a6e7-4f1b-f67f-17ef0006983c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 37ms/step\n"]}]},{"cell_type":"code","source":["print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmotYLLvSil3","executionInfo":{"status":"ok","timestamp":1683061622712,"user_tz":420,"elapsed":4,"user":{"displayName":"Parthiv Desai","userId":"01304148201832182673"}},"outputId":"598889c1-26f2-4fd5-b830-83a7eb46784b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cat\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1Yz3VvRXt7RyEYesnYM0uQV_7IwplMq9M","authorship_tag":"ABX9TyOU7OVRxN40Og9/UHWJwhFY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}